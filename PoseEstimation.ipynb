{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9323d057-835a-4177-85f4-6496d2e9a165",
   "metadata": {},
   "source": [
    "# Pose Estimation from Synthetic Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30657f0-241c-46e1-979d-a3d842a9f18c",
   "metadata": {},
   "source": [
    "Carico l'immagine output del processo di SuperGlue che risulta essere un file npz (una sorta di cartella zip degli array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "300cdaed-88c4-4b00-9204-ce558f2e4f40",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[335 336  -1 ...  -1  -1  -1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "path = \"../SuperGluePretrainedNetwork/MoonLu/MoonImg_Out12/Nadir_pitch_15_deg_matches.npz\"\n",
    "#path = \"MoonLu/MoonImg_Out/Nadir_pitch_15_deg_matches.npz\"\n",
    "npz = np.load(path)\n",
    "npz.files\n",
    "print(npz[\"matches\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc944c-bceb-4956-b01d-93c1df3859d2",
   "metadata": {},
   "source": [
    "Sapendo che: \n",
    "* Keypoint0 e Keypoint 1 sono i punti di maggior interesse delle due immagini prese in condierazione dal processo di SuperGlue\n",
    "* il tipo di dati risulta essere un array del tipo (N,2), ovvero N in base al totale numero di punti d'interesse trovati e 2 perchè relativi alla coordinata (x,y) nell'immagine\n",
    "\n",
    "\n",
    "Una volta presi i vettori di keypoint0 e keypoint1, devo darli in pasto a findEssentialMat() per trovare la matrce essenziale E.\n",
    "Solo che mi da un errore: OpenCV(4.10.0) D:\\bld\\libopencv_1726965773712\\work\\modules\\calib3d\\src\\five-point.cpp:459: error: (-215:Assertion failed) npoints >= 0 && points2.checkVector(2) == npoints && points1.type() == points2.type() in function 'cv::findEssentialMat'\n",
    "Quindi le strade da percorrere sono due, partendo dal presupposto che il typo di dati in input coincide con quello richiesto dalla funzione:\n",
    "\n",
    "1- Tagliare semplicemente il vettore di keypoint1 in modo da avere la stessa lunchezza di keypoint0\n",
    "\n",
    "2- Tagliarlo come in 1., ma riordinarlo anche usando gli indici in \"matches\"\n",
    "\n",
    "\n",
    "N.B. la lunghezza focale è da considerarsi in \"pixel units\", quindi lunghezza_focale/dimensione_pixel; il centro ottico considerato nel centro dell'immagine, quindi risoluzione/2 (uguale sia lungo x che lungo y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e655c2c-da07-4f7a-b65a-6db695bbd493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#METODO 1\n",
    "coord_1 = npz[\"keypoints0\"]\n",
    "coord_2 = npz[\"keypoints1\"][0:len(coord_1)]\n",
    "#print((coord_2))\n",
    "#print(len(coord_2))\n",
    "#print(coord_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "924f1913-9132-40ee-a82f-6e87621f1be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[261. 342.]\n",
      "[587. 342.]\n",
      "[60.  9.]\n",
      "[261. 342.]\n",
      "[587. 342.]\n",
      "[60.  9.]\n"
     ]
    }
   ],
   "source": [
    "#METODO 2\n",
    "coord_1 = npz[\"keypoints0\"]\n",
    "coord_2 = npz[\"keypoints1\"]\n",
    "#print(coord_2[335])\n",
    "#print(coord_2[336])\n",
    "#print(coord_2[2])\n",
    "\n",
    "#print(len(coord_1))\n",
    "#print(len(coord_2))\n",
    "#print(len(npz[\"matches\"]))\n",
    "\n",
    "\n",
    "for i in range(1,len(npz[\"matches\"])):\n",
    "    \n",
    "    if npz[\"matches\"][i-1] != -1:\n",
    "        index = npz[\"matches\"][i-1]\n",
    "        #print(index)\n",
    "        coord_2[i-1] = coord_2[index]\n",
    "\n",
    "coord_2 = coord_2[0:len(coord_1)]\n",
    "#print(coord_2[0])\n",
    "#print(coord_2[1])\n",
    "#print(coord_2[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18587ca0-60cf-4e32-93c8-c5f9c8fed9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = 6.013/(11.7e-3)\n",
    "#print(f)\n",
    "c = 1024/2\n",
    "\n",
    "CameraMat = np.array([\n",
    "    [f,0,c],\n",
    "    [0,f,c],\n",
    "    [0,0,1]\n",
    "], dtype=np.float32)\n",
    "#print(type(CameraMat))\n",
    "#print(npz[\"matches\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade9f42-4bbf-4d34-a12b-b6039870bbf3",
   "metadata": {},
   "source": [
    "Per ora stiamo lavorando col metodo 1\n",
    "\n",
    "Usiamo la fuzione findEssentialMat() per trovare la matrice essenziale utile al processo di RevorePose().\n",
    "Tale funzione l'ho usata nel modo più semplice (dando i principali input, lascianfo il resto di default; da questo viene fuori che la mask (vettore delle correlazioni) presenta la maggioranza di 0 (ovvero mancata associamento dei punti). Ho provato allora con diversi cambiamenti: usato pesi outdoor (come suggerito da Luca) e ci sono effettivamente molti più Keypoint e associazioni, cambiato il valore del threshold e della prob, ma il problema persiste\n",
    "\n",
    "Con metodo RANSAC, cambiando la prob, il numero di inlier non aumenta, mentre cambia cambiando il threshold: con threshold 1 ho 64 inlier, mentre threshold 3 ne ho 166.\n",
    "Con metodo LMEDS , nè probabilitò, nè threshold hanno influenza: ho in tutto 58 inlier, su un vettore lungo 1544 elementi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "869ecf16-762c-474a-8cb1-23bc967056b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145]\n",
      "1544\n"
     ]
    }
   ],
   "source": [
    "#from cv2 import findEssentialMat, recoverPose, RANSAC\n",
    "import cv2\n",
    "\n",
    "#E, mask = cv2.findEssentialMat(coord_1, coord_2, CameraMat, method = cv2.RANSAC, prob = 0.999 , threshold = 1.0)\n",
    "E, mask = cv2.findEssentialMat(coord_1, coord_2, CameraMat)\n",
    "\n",
    "np.set_printoptions(threshold=np.inf) #Per permettere di visualizzare l'intero vettore a schermo\n",
    "\n",
    "#print(type(E))\n",
    "print(sum(mask))\n",
    "print(len(mask))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7411e9-2b44-47a2-830e-ac33b447bfda",
   "metadata": {},
   "source": [
    "Plot per vedere graficamente come vengono associati i punti delle due immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ace16dc-acbc-4891-978d-ade385372e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "## Visualizza i punti delle due immagini\n",
    "#plt.figure(figsize=(10, 5))\n",
    "\n",
    "## Visualizza i punti della prima immagine\n",
    "#plt.subplot(1, 2, 1)\n",
    "#plt.scatter(coord_1[:, 0], coord_1[:, 1], color='blue', marker='o')\n",
    "#plt.title('Punti coord_1')\n",
    "#plt.xlim(0, 1024)\n",
    "#plt.ylim(0, 1024)\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "## Visualizza i punti della seconda immagine\n",
    "#plt.subplot(1, 2, 2)\n",
    "#plt.scatter(coord_2[:, 0], coord_2[:, 1], color='red', marker='o')\n",
    "#plt.title('Punti coord_2')\n",
    "#plt.xlim(0, 1024)\n",
    "#plt.ylim(0, 1024)\n",
    "#plt.gca().set_aspect('equal', adjustable='box')\n",
    "\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2f4ee-fc81-4b7d-bfa7-5158427eed1e",
   "metadata": {},
   "source": [
    "Prima porto i vettori e matrici ad avere lo stesso livello di precisione, per poi usarloi n RevorePose(), ma ottengo l'errore:\n",
    "OpenCV(4.10.0) D:\\bld\\libopencv_1726965773712\\work\\modules\\core\\src\\matmul.dispatch.cpp:356: error: (-215:Assertion failed) type == B.type() in function 'cv::gemm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc4d386-b66f-48e6-a2d2-5f3851702fc8",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\bld\\libopencv_1726965773712\\work\\modules\\core\\src\\matmul.dispatch.cpp:356: error: (-215:Assertion failed) type == B.type() in function 'cv::gemm'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m coord_2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mascontiguousarray(coord_2, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#Pose, R, T, mask = cv2.recoverPose(E, coord_1, coord_2, CameraMat)\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m retval, R, T, mask1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mrecoverPose(E, coord_1, coord_2, CameraMat)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.10.0) D:\\bld\\libopencv_1726965773712\\work\\modules\\core\\src\\matmul.dispatch.cpp:356: error: (-215:Assertion failed) type == B.type() in function 'cv::gemm'\n"
     ]
    }
   ],
   "source": [
    "E = E.astype(np.float32)\n",
    "coord_1 = np.ascontiguousarray(coord_1, dtype=np.float32)\n",
    "coord_2 = np.ascontiguousarray(coord_2, dtype=np.float32)\n",
    "\n",
    "#Pose, R, T, mask = cv2.recoverPose(E, coord_1, coord_2, CameraMat)\n",
    "retval, R, T, mask1 = cv2.recoverPose(E, coord_1, coord_2, CameraMat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
